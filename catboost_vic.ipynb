{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_validate, GridSearchCV, train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_25157/3536806131.py:1: DtypeWarning: Columns (9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"SBAnational.csv\")\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"SBAnational.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['MIS_Status'] = df.apply(\n",
    "    lambda row: 'P I F' if pd.isna(row['ChgOffDate']) else 'CHGOFF' \n",
    "    if pd.isna(row['MIS_Status']) else row['MIS_Status'],\n",
    "    axis=1\n",
    ")\n",
    "df = df.drop([\"LoanNr_ChkDgt\", \"Name\", \"ChgOffDate\", \"DisbursementDate\", \"BalanceGross\", \"ChgOffPrinGr\", \"SBA_Appv\"], axis=1)\n",
    "df['ApprovalDate'] = pd.to_datetime(df['ApprovalDate'], format='%d-%b-%y')\n",
    "\n",
    "df['ApprovalDate'] = df['ApprovalDate'].apply(\n",
    "    lambda x: x - pd.DateOffset(years=100) if x.year > 2014 else x)\n",
    "\n",
    "df['ApprovalFY'] = pd.to_numeric(df['ApprovalFY'], errors='coerce')\n",
    "df['ApprovalFY'] = df['ApprovalFY'].astype('Int64')  # Int64 permet d'avoir des NaN\n",
    "\n",
    "cols_to_convert = ['GrAppv', 'DisbursementGross']\n",
    "\n",
    "for col in cols_to_convert:\n",
    "    df[col] = df[col].astype(str)  # S'assure que c'est une string\n",
    "    df[col] = df[col].str.replace('[\\$,]', '', regex=True)  # Retire $ et ,\n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce')  # Convertit en float\n",
    "\n",
    "df['State'] = df['State'].fillna(df['BankState'])\n",
    "recession_start = pd.Timestamp('2007-12-01')\n",
    "recession_end = pd.Timestamp('2009-06-30')\n",
    "df['Recession'] = ((df['ApprovalDate'] >= recession_start) & (df['ApprovalDate'] <= recession_end)).astype(int)\n",
    "# df['NewExist'] = df['NewExist'].map({2: 1, 1: 0, 0: np.nan})\n",
    "# df['UrbanRural'] = df['UrbanRural'].map({2: 1, 1: 0, 0: np.nan})\n",
    "df['HasFranchise'] = (df['FranchiseCode'] >= 100).astype(int)\n",
    "df['RevLineCr'] = df['RevLineCr'].apply(lambda x: x if x in ['Y', 'N'] else np.nan)  # Garde seulement Y et N, sinon NaN\n",
    "df = df[df['RevLineCr'].notnull()]\n",
    "df['LowDoc'] = df['LowDoc'].apply(lambda x: x if x in ['Y', 'N'] else np.nan)  # Garde seulement Y et N, sinon NaN\n",
    "df = df[df['LowDoc'].notnull()]\n",
    "df[\"NAICS\"] = df[\"NAICS\"].astype(str).str[:2]\n",
    "df['NAICS'] = df['NAICS'].replace('0', np.nan)\n",
    "df = df[df['NAICS'].notnull()]\n",
    "df = df[df['Bank'].notnull()]\n",
    "df = df[df['State'].notnull()]\n",
    "df = df.drop(['DisbursementGross','City','Zip','BankState','ApprovalDate','ApprovalFY','FranchiseCode'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_of_interest = [\n",
    "    'State', 'Bank', 'NAICS', 'Term', 'NoEmp', 'NewExist', 'CreateJob',\n",
    "       'RetainedJob', 'UrbanRural', 'RevLineCr', 'LowDoc', \n",
    "       'GrAppv', 'Recession', 'HasFranchise'\n",
    "    ]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "data = df\n",
    "\n",
    "target_name = \"MIS_Status\"\n",
    "X, y = (\n",
    "    data[features_of_interest],\n",
    "    data[target_name]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=True, test_size=0.1, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         N\n",
       "1         N\n",
       "2         N\n",
       "5         N\n",
       "7         N\n",
       "         ..\n",
       "899145    Y\n",
       "899146    N\n",
       "899157    N\n",
       "899160    Y\n",
       "899161    N\n",
       "Name: RevLineCr, Length: 461019, dtype: object"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X['RevLineCr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttest: 0.9022034\tbest: 0.9022034 (0)\ttotal: 220ms\tremaining: 1m 49s\n",
      "100:\ttest: 0.9758425\tbest: 0.9758425 (100)\ttotal: 16.8s\tremaining: 1m 6s\n",
      "200:\ttest: 0.9798300\tbest: 0.9798300 (200)\ttotal: 33.7s\tremaining: 50.1s\n",
      "300:\ttest: 0.9814191\tbest: 0.9814191 (300)\ttotal: 50.7s\tremaining: 33.5s\n",
      "400:\ttest: 0.9822350\tbest: 0.9822369 (399)\ttotal: 1m 7s\tremaining: 16.7s\n",
      "499:\ttest: 0.9827398\tbest: 0.9827398 (499)\ttotal: 1m 24s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.9827398247\n",
      "bestIteration = 499\n",
      "\n",
      "AUC: 0.9827\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "\n",
    "cat_features = ['NAICS', 'Bank', 'State', 'RevLineCr', 'LowDoc']\n",
    "\n",
    "# Initialisation du modèle avec AUC comme métrique\n",
    "model = CatBoostClassifier(\n",
    "    iterations=500, \n",
    "    learning_rate=0.1, \n",
    "    depth=6, \n",
    "    cat_features=cat_features, \n",
    "    eval_metric=\"AUC\",  # Utilisation de l'AUC\n",
    "    verbose=100\n",
    ")\n",
    "\n",
    "# Entraînement\n",
    "model.fit(X_train, y_train, eval_set=(X_test, y_test), early_stopping_rounds=50, verbose=100)\n",
    "\n",
    "# Prédiction des probabilités pour calculer l'AUC\n",
    "y_pred_proba = model.predict_proba(X_test)[:, 1]  # Probabilité de la classe positive\n",
    "\n",
    "# Calcul de l'AUC\n",
    "auc_score = roc_auc_score(y_test, y_pred_proba)\n",
    "print(f\"AUC: {auc_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.9442760\ttest: 0.9446696\tbest: 0.9446696 (0)\ttotal: 201ms\tremaining: 1m 40s\n",
      "100:\tlearn: 0.9566834\ttest: 0.9563334\tbest: 0.9563334 (100)\ttotal: 16.8s\tremaining: 1m 6s\n",
      "200:\tlearn: 0.9620437\ttest: 0.9614662\tbest: 0.9614662 (200)\ttotal: 32.3s\tremaining: 48s\n",
      "300:\tlearn: 0.9645826\ttest: 0.9642194\tbest: 0.9642194 (299)\ttotal: 47.9s\tremaining: 31.6s\n",
      "400:\tlearn: 0.9659516\ttest: 0.9655474\tbest: 0.9655474 (400)\ttotal: 1m 3s\tremaining: 15.8s\n",
      "499:\tlearn: 0.9671432\ttest: 0.9663558\tbest: 0.9663558 (499)\ttotal: 1m 21s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.9663557537\n",
      "bestIteration = 499\n",
      "\n",
      "Précision sur l'ensemble de test : 0.9538\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "\n",
    "cat_features = ['NAICS', 'Bank', 'State', 'RevLineCr', 'LowDoc']\n",
    "\n",
    "# Initialisation du modèle avec AUC comme métrique\n",
    "model = CatBoostClassifier(\n",
    "    iterations=500, \n",
    "    learning_rate=0.1, \n",
    "    depth=6, \n",
    "    cat_features=cat_features, \n",
    "    eval_metric='Precision',  # Utilisation de l'AUC\n",
    "    verbose=100\n",
    ")\n",
    "\n",
    "# Entraînement\n",
    "model.fit(X_train, y_train, eval_set=(X_test, y_test), early_stopping_rounds=50, verbose=100)\n",
    "\n",
    "precision = model.score(X_test, y_test)\n",
    "print(f'Précision sur l\\'ensemble de test : {precision:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
